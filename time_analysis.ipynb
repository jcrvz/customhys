{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "from mpmath import *\n",
    "from decimal import Decimal\n",
    "\n",
    "import tools as tl\n",
    "import benchmark_func as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_folder = \"./data_files/ml_models_times/\"\n",
    "files = os.listdir(ml_model_folder)\n",
    "files = [file for file in files if 'DS_S' not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, ['50D', '2D', '10D', '30D'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = list(set(file.split('-')[1] for file in files))\n",
    "\n",
    "problems = list(set(file.split('-')[0] for file in files))\n",
    "len(problems), dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_label = 'default_nn_best_double_lstm'\n",
    "pred_dyn_time = '_mhs_dynamic_time_logs'\n",
    "pred_nn_time = '_mhs_time_prediction_logs'\n",
    "nn_train_time = '-mem60_log_time'\n",
    "nn_train_epoch = '-mem60_log'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_training = []\n",
    "for problem in problems:\n",
    "  for dimension in dimensions:\n",
    "    kk = ml_model_folder+'-'.join([problem, dimension, file_label+nn_train_time])+'.csv'\n",
    "    df = pd.read_csv(kk,index_col=0)\n",
    "    time_training.append(sum(df['time'])/60)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.065762639339116"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(time_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0658 +- 1.1422 min\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.mean(time_training):.4f} +- {np.std(time_training):.4f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.4590216199557"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(time_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.90218506924187"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(time_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.254574124080442"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(time_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nn = []\n",
    "prediction_dyn = []\n",
    "model_size = []\n",
    "for problem in problems:\n",
    "  for dimension in dimensions:\n",
    "    kk = ml_model_folder+'-'.join([problem, dimension, file_label+pred_nn_time])+'.csv'\n",
    "    df = pd.read_csv(kk,index_col=0)\n",
    "    prediction_nn.append(list(df['time']))\n",
    "\n",
    "    kk = ml_model_folder+'-'.join([problem, dimension, file_label+pred_dyn_time])+'.csv'\n",
    "    df = pd.read_csv(kk,index_col=0)\n",
    "    prediction_dyn.append(list(df['time']))\n",
    "    \n",
    "    kk = ml_model_folder+'-'.join([problem, dimension, file_label])+'.h5'\n",
    "    szmb = os.path.getsize(kk)\n",
    "    model_size.append(szmb)\n",
    "    \n",
    "    \n",
    "prediction_nn = sum(prediction_nn, [])\n",
    "prediction_dyn = sum(prediction_dyn, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kk = tl.read_json('dlstm_cec2005_results.json')\n",
    "application_dsltm = kk['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kk = tl.read_json('bmhs_cec2005_results.json')\n",
    "generation_bmhs = kk['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(arr):\n",
    "  print(f'{np.mean(arr):.4f} +- {np.std(arr):.4f}')\n",
    "  print(\"Mean:\", np.mean(arr))\n",
    "  print(\"Median:\", np.median(arr))\n",
    "  print(\"Max:\", np.max(arr))\n",
    "  print(\"Min:\", np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1150 +- 0.1330\n",
      "Mean: 0.11503951610396822\n",
      "Median: 0.08288715346666702\n",
      "Max: 0.9077741125000007\n",
      "Min: 0.0028204264000000496\n"
     ]
    }
   ],
   "source": [
    "statistics(np.array(application_dsltm)/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1207 +- 9.8421\n",
      "Mean: 7.120677338597865\n",
      "Median: 3.9960812079998504\n",
      "Max: 75.5595616669998\n",
      "Min: 1.0285562089998166\n"
     ]
    }
   ],
   "source": [
    "statistics(generation_bmhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7847 +- 0.4637\n",
      "Mean: 0.7847310644040911\n",
      "Median: 0.685302846133709\n",
      "Max: 6.7967276107519865\n",
      "Min: 0.1729795932769775\n"
     ]
    }
   ],
   "source": [
    "statistics(prediction_dyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8644 +- 1.7053\n",
      "Mean: 2.864399075801702\n",
      "Median: 3.0174137512221932\n",
      "Max: 12.9883802421391\n",
      "Min: 0.1112331077456474\n"
     ]
    }
   ],
   "source": [
    "statistics(prediction_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155844.0 +- 0.0\n",
      "Mean: 155844.0\n",
      "Median: 155844.0\n",
      "Max: 155844\n",
      "Min: 155844\n"
     ]
    }
   ],
   "source": [
    "statistics(model_size) # In bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_profiler import model_profiler\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data_files/ml_models/Ackley1-2D-default_nn_best_double_lstm.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 01:26:58.555176: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-10 01:26:58.555376: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Profile                    | Value   | Unit    |\n",
      "|----------------------------------|---------|---------|\n",
      "| Selected GPUs                    | ['0']   | GPU IDs |\n",
      "| No. of FLOPs                     | 0.0     | BFLOPs  |\n",
      "| GPU Memory Requirement           | 0.0002  | GB      |\n",
      "| Model Parameters                 | 0.0093  | Million |\n",
      "| Memory Required by Model Weights | 0.0356  | MB      |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 01:28:24.913328: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-10 01:28:24.913386: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/josetapia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/model_profiler/profiler.py:72: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.asarray(values).reshape(-1,1),\n"
     ]
    }
   ],
   "source": [
    "profile = model_profiler(model, 32)\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 20)            1760      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 205)               4305      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,345\n",
      "Trainable params: 9,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from keras import backend as K\n",
    "    except:\n",
    "        from tensorflow.keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        out_shape = l.output_shape\n",
    "        if type(out_shape) is list:\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "        number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "        number_size = 8.0\n",
    "\n",
    "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 10) + internal_model_mem_count\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002046861"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_memory_usage(32, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13a1a4c7f867d5ec33b811066f10a0e467cde7b9dca366a8ff958366b3d34ba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
